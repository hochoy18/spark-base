# [Spark Configuration](http://spark.apache.org/docs/latest/configuration.html)


spark 能配置的三处

 - 通过设置 [spark Properties](#1) 的 SparkConf 对象或 Java 系统属性
 - conf/spark-env.sh 等 [环境变量](#2)
 - [Logging](#3) can be configured through log4j.properties.

##  <span id = "1"> Spark Properties </span>
Spark Properties 能控制大部分的Application 设置，同时也为每个Application独立设置 配置。这些配置可以直接通过SparkConf设置（支持一些常用属性配置，e.g:master URL and  application name），也能通过 SparkConf#set() 方法设置。例如

```
val conf = new SparkConf()
             .setMaster("local[2]")
             .setAppName("CountingSheep")
val sc = new SparkContext(conf)
```
>### <span id="1.1"> Dynamically Loading Spark Properties </span>
某些场景中，可能要避免在 SparkConf 中对某些配置进行硬编码，比如说，你可能想使用不同 主机或不同的内存运行用一个Application，spark允许您简单地创建一个空的SparkConf。
```
val sc = new SparkContext(new SparkConf())
```
也可以在程序运行时提供配置值
```
./bin/spark-submit  
    --name  "My app" 
    --master local[4] 
    --conf spark.eventLog.enabled=false
    --conf "spark.executor.extraJavaOptions=-XX:+PrintGCDetails -XX:PrintGCTimeStamps" myApp.jar
```
```spark-shell``` 以及 ```spark-submit``` 有两种动态加载配置的方式：第一种就是通过命令行，就像 上面的```--master```, ```spark-submit``` 使用 ```--conf``` 标志可以接收任意的spark属性。 使用特定的属性值也会起到特定的作用， ``` ./bin/spark-submit --help``` 会列出```spark-submit```整个选项。

```bin/spark-submit``` 也可以从 ```conf/spark-defaults.conf``` 中读取配置项，这个配置文件中的每一行都包含由空格分隔的 key 值和value值，例如：
```
spark.master            spark://5.6.7.8:7077
spark.executor.memory   4g
spark.eventLog.enabled  true
spark.serializer        org.apache.spark.serializer.KryoSerializer
```

spark 配置属性主要分为两种：一种是与部署相关的，诸如"spark.driver.memory","spark.executor.instances",
>### Viewing Spark Properties



>### Available Properties

>>#### Application Properties

>>#### Runtime Environment

>>#### Shuffle Behavior
>>#### Spark UI
>>#### Compression and Serialization
>>#### Memory Management
>>#### Execution Behavior
>>#### Networking
>>#### Scheduling
>>#### Dynamic Allocation

>>#### Security
>>#### Spark SQL
>>#### Spark Streaming
>>#### SparkR
>>#### GraphX
>>#### Deploy
>>#### Cluster Managers
>>>##### YARN
>>>##### Mesos
>>>##### Kubernetes
>>>##### Standalone Mode





## <span id = "2"> Environment Variables</span>

## <span id = "3"> Configuring Logging</span>

## Overriding configuration directory


## Inheriting Hadoop Cluster Configuration

## Custom Hadoop/Hive Configuration