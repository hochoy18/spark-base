#[硬件配置](http://spark.apache.org/docs/latest/hardware-provisioning.html)

## Storage Systems
可能的话，Spark节点与HDFS节点是一一对应的，可使用spark的standalone 部署模式或者直接运行在集群的cluster manager上（yarn 或 Mesos)  
如果做不到，那至少保证Spark节点与HDFS节点是一个局域网内

## Local Disks
在spark的计算过程中会有中间结果输出到磁盘（本地）因此也就需要一部分的本地存储空间来接收，
一般推荐每个节点有4-8个硬盘，不配置RAID（就如同不同的挂载点）

## Memory
通常来说，spark可以在 8 - 数百个G的内存的机器上很好的运行，但是我们建议给spark 不超过75% 的内存，剩下的留给操作系统和buffer缓存使用。
使用多少内存取决于你应用程序的数据量，

## Network
根据经验，当数据在内存中， 使用万兆网卡程序将运行的更快，特别是“distributed reduce” application 
例如 group-bys 减少，reduce-bys 和SQL的join ，在一个任何给定的application ，
你能够通过UI查看Spark的shuffles的过程及多大的数据执行shuffles。


## CPU Cores
Spark可以很好地扩展到每台计算机数十个CPU内核，因为它在线程之间执行的共享最少。您可能应该为每台机器配置至少**8-16**个内核。
根据工作负载的CPU成本，您可能还需要更多：一旦数据存储在内存中，大多数应用程序就会受到CPU或网络的限制。