### 3.3 RDD的转换和DAG的生成

#### 3.3.1 RDD 的依赖关系

- 窄依赖： 父RDD的每个分区只被子RDD的一个分区所使用
   - OneToOneDependency
   - RangeDependency
   - PruneDependency
   
- 宽依赖： 父RDD的每个分区都可能被多个子RDD分区所使用，子RDD分区通常对应所有的父RDD分区
   - ShuffleDependency
   
   
#### 3.3.2 DAG 的生成
 - 首先，根据依赖关系的不同将DAG划分为不同的阶段（Stage）
    - 对于窄依赖，由于Partition依赖关系的确定性， Partition的转换处理就可以在同一个线程里完成，窄依赖被Spark划分到同一个执行阶段；
    - 对于宽依赖，由于Shuffle的存在，只能在parent RDD(s)Shuffle处理完成后，才能开始接下来的计算  
    因此宽依赖就是Spark划分Stage的依据，即Spark根据宽依赖将DAG划分为不同的Stage。
 - 在一个Stage内部，每个Partition都会被分配一个计算任务（Task），这些Task是可以并行执行的。Stage之间根据依赖关系变成了一个大粒度的DAG，这个DAG的执行顺序也是从前向后的
 
 
 #### 3.3.3 Word Count的RDD转换和DAG划分的逻辑视图
  转换操作reduceByKey时会触发一个Shuffle（洗牌）的过程。在Shuffle开始之前，有一个本地聚合的过程，比如第三个分片的（e，1）（e，1）聚合成了（e，2）。
  Shuffle的结果是为下游的Task生成了三个分片，这三个分片就构成了ShuffledRDD。之后在做了一个聚合之后，就生成了结果的RDD。