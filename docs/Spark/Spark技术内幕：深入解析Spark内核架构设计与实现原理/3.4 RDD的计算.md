### 3.4 RDD 的计算


#### 3.4.1 Task 简介

 - 原始的RDD经过一系列转换后，会在最后一个RDD上触发一个动作，这个动作会生成一个Job。在Job被划分为一批计算任务（Task）后，这批Task会被提交到集群上的计算节点去计算。
 计算节点执行计算逻辑的部分称为Executor。Executor在准备好Task的运行时环境后，会通过调用org.apache.spark.scheduler.Task#run来执行计算。Spark的Task分为两种：
    - org.apache.spark.scheduler.ShuffleMapTask
    - org.apache.spark.scheduler.ResultTask