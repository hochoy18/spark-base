### 3.2 什么是RDD

每个RDD有5个主要属性：
   - A list of partitions 【一组分片（partitions）】//一个分区列表
   - A function for computing each split 【一个**计算每个分区**的函数】
   - A list of dependencies on other RDDs 【RDD间的依赖关系】// 依赖于其他RDD的列表
   - Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned) 【key-value 类型RDD的分区器】
   - Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)【每个分区都有一个优先位置列表】
      - 最优的位置去计算，也就是数据的本地性，计算每个split时，在split所在机器的本地上运行task是最好的，避免了数据的移动；split有多个副本，所以preferred location不止一个


#### 3.2.1 RDD的创建  

- 可以通过两种方式创建RDD
   - 由一个已经存在的Scala集合创建
```
    val data = Array(1, 2, 3, 4, 5)
    val distData = sc.parallelize(data)
```
   - 由外部存储系统的数据集创建，包括本地的文件系统，还有所有Hadoop支持的数据集，比如HDFS、Cassandra、HBase、Amazon S3等
```
    val distFile = sc.textFile("data.txt")
```

#### 3.2.2 RDD 的转换

#### 3.2.3 RDD 的动作

#### 3.2.4 [RDD的缓存](http://spark.apache.org/docs/2.3.3/rdd-programming-guide.html#rdd-persistence)

- 通过persist()或cache()方法可以标记一个要被持久化的RDD，一旦首次被触发，该RDD将会被保留在计算节点的内存中并重用。  

- 假设首先进行了RDD0→RDD1→RDD2的计算作业，那么计算结束时，RDD1就已经缓存在系统中了。在进行RDD0→RDD1→RDD3的计算作业时，由于RDD1已经缓存在系统中，
因此RDD0→RDD1的转换不会重复进行，计算作业只须进行RDD1→RDD3的计算就可以了，因此计算速度可以得到很大提升  

- 缓存有可能丢失，或者存储于内存的数据由于内存不足而被删除。RDD的缓存的容错机制保证了即使缓存丢失也能保证计算的正确执行。通过基于RDD的一系列的转换，丢失的数据会被重算。
RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition。

Spark also automatically persists some intermediate data in shuffle operations (e.g. reduceByKey), even without users calling persist. 
This is done to avoid recomputing the entire input if a node fails during the shuffle. We still recommend users call persist on the resulting RDD 
if they plan to reuse it.(**即使用户没有调用persist() 来做持久化，Spark也会在触发 shuffle 算子是持久化一些中间数据，这是为了避免 某个节点在shuffle时挂掉时的重复计算**)

- [Removing Data](http://spark.apache.org/docs/2.3.3/rdd-programming-guide.html#removing-data)  
   Spark automatically monitors cache usage on each node and drops out old data partitions in a least-recently-used (LRU) fashion.
   Spark 会自动监控每个节点的缓存使用情况，并以LRU的方式删除旧数据分区，如果要手动删除RDD而不是等待它自动脱离缓存，请使用```RDD.unpersist()```方法。


#### 3.2.5 RDD的检查点
缓存是在计算结束后，直接将计算结果通过用户定义的存储级别（存储级别定义了缓存存储的介质，现在支持内存、本地文件系统和Tachyon）写入不同的介质。
而检查点不同，它是在计算完成后，重新建立一个Job来计算。为了避免重复计算，推荐先将RDD缓存，这样就能保证检查点的操作可以快速完成。
用户可以通过调用```org.apache.spark.rdd.RDD#checkpoint()```来指定RDD需要检查点机制。

```
    def main(args: Array[String]) {
        val sparkConf = new SparkConf().setAppName("WordCount")
        val sc = new SparkContext(sparkConf)
        //通过 SparkContext 对 checkpoint 设置 hdfs目录，不设置会报错
        sc.setCheckpointDir("hdfs://zyb01:9000/checkpoint")

        val reduceRdd = sc.textFile(args(0)).flatMap(_.split(" "))
          .map((_, 1)).reduceByKey(_ + _)

        //对 reduceRdd 调用 checkpoint 把数据保存到 hdfs 
        reduceRdd.checkpoint()

        //action
        reduceRdd.saveAsTextFile(args(1))
    }
```

















