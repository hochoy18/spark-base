
    Scheduler（任务调度）模块作为Spark Core的核心模块之一，充分地体现了与MapReduce完全不同的设计思想。Spark对于DAG（Directed Acyclic Graph，有向无环图）的实现及不同执行阶段的划分和任务的提交执行，
    充分体现了其设计的优雅和高效。本章主要介绍任务调度，即组成应用的多个Job之间如何分配计算资源。

[spark核心机制](https://blog.csdn.net/qq_1018944104/article/details/85714631)

### 4.1 模块概述

#### 4.1.1 整体架构

- 任务调度模块主要包含两大部分，即***DAGScheduler***和***TaskScheduler***，它们负责**将用户提交的计算任务按照DAG划分为不同的阶段**并且**将不同阶段的计算任务提交到集群进行最终的计算**。
- **DAGScheduler**主要负责**分析用户提交的应用**，并根据计算任务的依赖关系**建立DAG**，然后**将DAG划分为不同的Stage**（阶段），
其中每个Stage由可以并发执行的一组Task构成，这些Task的执行逻辑完全相同，只是作用于不同的数据。
- 在DAGScheduler将这组Task划分完成后，会将这组Task提交到 **TaskScheduler**。
- TaskScheduler通过**ClusterManager**在集群中的某个Worker的Executor上**启动任务**。


#### 4.1.2 Scheduler的实现概
任务调度模块涉及的最重要的三个类是：
- org.apache.spark.scheduler.DAGScheduler

- org.apache.spark.scheduler.SchedulerBackend 
   - 分配当前可用的资源，具体就是向当前等待分配计算资源的Task分配计算资源（即Executor），并且在分配的Executor上启动Task，完成计算的调度过程。
   - SchedulerBackend#reviveOffers(): SchedulerBackend 把自己手头上的可用资源交给TaskScheduler，TaskScheduler 根据调度策略分配给排队的任务，
   返回一批可执行的任务描述，SchedulerBackend 负责 launchTask，即最终把 task 塞到了 executor 模型上，executor 里的线程池会执行 task 的 run()
     
- org.apache.spark.scheduler.TaskScheduler
   - 作用是为创建它的SparkContext**调度任务**，即从DAGScheduler接收不同Stage的任务，并且**向集群提交这些任务**，并为执行特别慢的任务启动备份任务。
   - 维护 task 和 executor 对应关系，executor 和物理资源对应关系，在排队的 task 和正在跑的task。维护内部一个任务队列，根据 FIFO 或 Fair 策略，调度任务